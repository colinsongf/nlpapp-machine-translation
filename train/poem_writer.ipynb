{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:40.319601Z",
     "start_time": "2019-11-12T09:30:40.311265Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os, json, codecs\n",
    "import tensorflow as tf\n",
    "from bert4keras.bert import build_bert_model\n",
    "from bert4keras.utils import Tokenizer, load_vocab, parallel_apply\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:41.734410Z",
     "start_time": "2019-11-12T09:30:41.731509Z"
    }
   },
   "outputs": [],
   "source": [
    "config_path = '/opt/developer/wp/wzcq/roberta_wwm/bert_config.json'\n",
    "checkpoint_path = '/opt/developer/wp/wzcq/roberta_wwm/bert_model.ckpt'\n",
    "dict_path = '/opt/developer/wp/wzcq/roberta_wwm/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:42.411741Z",
     "start_time": "2019-11-12T09:30:42.389205Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_token_dict(token_file):\n",
    "    with open(token_file,\"r\") as f:\n",
    "        token_list = f.readlines()\n",
    "        token_dict = {word.strip():id_ for id_,word in enumerate(token_list)}\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "class OurTokenizer(Tokenizer):\n",
    "    def _tokenize(self, text):\n",
    "        R = []\n",
    "        for c in text:\n",
    "            if c in self._token_dict:\n",
    "                R.append(c)\n",
    "            elif self._is_space(c):\n",
    "                R.append('[unused1]') # space类用未经训练的[unused1]表示\n",
    "            else:\n",
    "                R.append('[UNK]') # 剩余的字符是[UNK]\n",
    "        return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = get_token_dict(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = OurTokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2769, 1762, 677, 3862, 102], [0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('我在上海')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:44.263110Z",
     "start_time": "2019-11-12T09:30:44.259173Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./ci/ci.song.1000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:54.204599Z",
     "start_time": "2019-11-12T09:30:54.195653Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_ci_examples(input_file):\n",
    "    \"\"\"Read a tang poet json file into a list \"\"\"\n",
    "    with tf.gfile.Open(input_file, \"r\") as reader:\n",
    "        input_data = json.load(reader)\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "        ci = []\n",
    "        rhythmic = entry[\"rhythmic\"]\n",
    "        #print(\"rhythmic\",rhythmic)\n",
    "        ci.append(rhythmic+\":\")\n",
    "        s = \"\"\n",
    "        for paragraph in entry[\"paragraphs\"]:   \n",
    "            #print(\"paragraphs\",paragraph)\n",
    "            s += paragraph\n",
    "        ci.append(s)\n",
    "        examples.append(ci)    \n",
    "    return examples     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:55.257925Z",
     "start_time": "2019-11-12T09:30:55.243595Z"
    }
   },
   "outputs": [],
   "source": [
    "data = read_ci_examples(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['踏莎行:',\n",
       "  '嵩峤云高，洛川波暖。举头乔木森无断。□□□雨绝风尘，小桥频过春渠满。□□离宫，□棱斗焕。万家罗绮多游伴。□□□□自风□，□□是处喧弦管。']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:30:56.172409Z",
     "start_time": "2019-11-12T09:30:56.162801Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding(x):\n",
    "    \"\"\"padding至batch内的最大长度\n",
    "    \"\"\"\n",
    "    ml = max([len(i) for i in x])\n",
    "    return np.array([i + [0] * (ml - len(i)) for i in x])\n",
    "\n",
    "\n",
    "def data_generator():\n",
    "    while True:\n",
    "        X, S = [], []\n",
    "        for t,d in data:\n",
    "            x, s = tokenizer.encode(t,d)\n",
    "            X.append(x)\n",
    "            S.append(s)\n",
    "            if len(X) == batch_size:\n",
    "                X = padding(X)\n",
    "                S = padding(S)\n",
    "                yield [X, S], None\n",
    "                X, S = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.encode(data[1][0],data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('菩萨蛮:', '子规啼破城楼月。画船晓载笙歌发。两岸荔枝红。万家烟雨中。佳人相对泣。泪下罗衣湿。从此信音稀。岭南无雁飞。')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][0],data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:32:34.946141Z",
     "start_time": "2019-11-12T09:30:58.556218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> searching: bert/embeddings/word_embeddings, found name: bert/embeddings/word_embeddings\n",
      "==> searching: bert/embeddings/position_embeddings, found name: bert/embeddings/position_embeddings\n",
      "==> searching: bert/embeddings/token_type_embeddings, found name: bert/embeddings/token_type_embeddings\n",
      "==> searching: bert/embeddings/LayerNorm/gamma, found name: bert/embeddings/LayerNorm/gamma\n",
      "==> searching: bert/embeddings/LayerNorm/beta, found name: bert/embeddings/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_0/attention/self/query/kernel, found name: bert/encoder/layer_0/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_0/attention/self/query/bias, found name: bert/encoder/layer_0/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_0/attention/self/key/kernel, found name: bert/encoder/layer_0/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_0/attention/self/key/bias, found name: bert/encoder/layer_0/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_0/attention/self/value/kernel, found name: bert/encoder/layer_0/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_0/attention/self/value/bias, found name: bert/encoder/layer_0/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_0/attention/output/dense/kernel, found name: bert/encoder/layer_0/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_0/attention/output/dense/bias, found name: bert/encoder/layer_0/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_0/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_0/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_0/attention/output/LayerNorm/beta, found name: bert/encoder/layer_0/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_0/intermediate/dense/kernel, found name: bert/encoder/layer_0/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_0/intermediate/dense/bias, found name: bert/encoder/layer_0/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_0/output/dense/kernel, found name: bert/encoder/layer_0/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_0/output/dense/bias, found name: bert/encoder/layer_0/output/dense/bias\n",
      "==> searching: bert/encoder/layer_0/output/LayerNorm/gamma, found name: bert/encoder/layer_0/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_0/output/LayerNorm/beta, found name: bert/encoder/layer_0/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_1/attention/self/query/kernel, found name: bert/encoder/layer_1/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_1/attention/self/query/bias, found name: bert/encoder/layer_1/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_1/attention/self/key/kernel, found name: bert/encoder/layer_1/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_1/attention/self/key/bias, found name: bert/encoder/layer_1/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_1/attention/self/value/kernel, found name: bert/encoder/layer_1/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_1/attention/self/value/bias, found name: bert/encoder/layer_1/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_1/attention/output/dense/kernel, found name: bert/encoder/layer_1/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_1/attention/output/dense/bias, found name: bert/encoder/layer_1/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_1/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_1/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_1/attention/output/LayerNorm/beta, found name: bert/encoder/layer_1/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_1/intermediate/dense/kernel, found name: bert/encoder/layer_1/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_1/intermediate/dense/bias, found name: bert/encoder/layer_1/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_1/output/dense/kernel, found name: bert/encoder/layer_1/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_1/output/dense/bias, found name: bert/encoder/layer_1/output/dense/bias\n",
      "==> searching: bert/encoder/layer_1/output/LayerNorm/gamma, found name: bert/encoder/layer_1/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_1/output/LayerNorm/beta, found name: bert/encoder/layer_1/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_2/attention/self/query/kernel, found name: bert/encoder/layer_2/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_2/attention/self/query/bias, found name: bert/encoder/layer_2/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_2/attention/self/key/kernel, found name: bert/encoder/layer_2/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_2/attention/self/key/bias, found name: bert/encoder/layer_2/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_2/attention/self/value/kernel, found name: bert/encoder/layer_2/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_2/attention/self/value/bias, found name: bert/encoder/layer_2/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_2/attention/output/dense/kernel, found name: bert/encoder/layer_2/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_2/attention/output/dense/bias, found name: bert/encoder/layer_2/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_2/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_2/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_2/attention/output/LayerNorm/beta, found name: bert/encoder/layer_2/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_2/intermediate/dense/kernel, found name: bert/encoder/layer_2/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_2/intermediate/dense/bias, found name: bert/encoder/layer_2/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_2/output/dense/kernel, found name: bert/encoder/layer_2/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_2/output/dense/bias, found name: bert/encoder/layer_2/output/dense/bias\n",
      "==> searching: bert/encoder/layer_2/output/LayerNorm/gamma, found name: bert/encoder/layer_2/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_2/output/LayerNorm/beta, found name: bert/encoder/layer_2/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_3/attention/self/query/kernel, found name: bert/encoder/layer_3/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_3/attention/self/query/bias, found name: bert/encoder/layer_3/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_3/attention/self/key/kernel, found name: bert/encoder/layer_3/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_3/attention/self/key/bias, found name: bert/encoder/layer_3/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_3/attention/self/value/kernel, found name: bert/encoder/layer_3/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_3/attention/self/value/bias, found name: bert/encoder/layer_3/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_3/attention/output/dense/kernel, found name: bert/encoder/layer_3/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_3/attention/output/dense/bias, found name: bert/encoder/layer_3/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_3/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_3/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_3/attention/output/LayerNorm/beta, found name: bert/encoder/layer_3/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_3/intermediate/dense/kernel, found name: bert/encoder/layer_3/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_3/intermediate/dense/bias, found name: bert/encoder/layer_3/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_3/output/dense/kernel, found name: bert/encoder/layer_3/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_3/output/dense/bias, found name: bert/encoder/layer_3/output/dense/bias\n",
      "==> searching: bert/encoder/layer_3/output/LayerNorm/gamma, found name: bert/encoder/layer_3/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_3/output/LayerNorm/beta, found name: bert/encoder/layer_3/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_4/attention/self/query/kernel, found name: bert/encoder/layer_4/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_4/attention/self/query/bias, found name: bert/encoder/layer_4/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_4/attention/self/key/kernel, found name: bert/encoder/layer_4/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_4/attention/self/key/bias, found name: bert/encoder/layer_4/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_4/attention/self/value/kernel, found name: bert/encoder/layer_4/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_4/attention/self/value/bias, found name: bert/encoder/layer_4/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_4/attention/output/dense/kernel, found name: bert/encoder/layer_4/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_4/attention/output/dense/bias, found name: bert/encoder/layer_4/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_4/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_4/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_4/attention/output/LayerNorm/beta, found name: bert/encoder/layer_4/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_4/intermediate/dense/kernel, found name: bert/encoder/layer_4/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_4/intermediate/dense/bias, found name: bert/encoder/layer_4/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_4/output/dense/kernel, found name: bert/encoder/layer_4/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_4/output/dense/bias, found name: bert/encoder/layer_4/output/dense/bias\n",
      "==> searching: bert/encoder/layer_4/output/LayerNorm/gamma, found name: bert/encoder/layer_4/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_4/output/LayerNorm/beta, found name: bert/encoder/layer_4/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_5/attention/self/query/kernel, found name: bert/encoder/layer_5/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_5/attention/self/query/bias, found name: bert/encoder/layer_5/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_5/attention/self/key/kernel, found name: bert/encoder/layer_5/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_5/attention/self/key/bias, found name: bert/encoder/layer_5/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_5/attention/self/value/kernel, found name: bert/encoder/layer_5/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_5/attention/self/value/bias, found name: bert/encoder/layer_5/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_5/attention/output/dense/kernel, found name: bert/encoder/layer_5/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_5/attention/output/dense/bias, found name: bert/encoder/layer_5/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_5/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_5/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_5/attention/output/LayerNorm/beta, found name: bert/encoder/layer_5/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_5/intermediate/dense/kernel, found name: bert/encoder/layer_5/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_5/intermediate/dense/bias, found name: bert/encoder/layer_5/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_5/output/dense/kernel, found name: bert/encoder/layer_5/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_5/output/dense/bias, found name: bert/encoder/layer_5/output/dense/bias\n",
      "==> searching: bert/encoder/layer_5/output/LayerNorm/gamma, found name: bert/encoder/layer_5/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_5/output/LayerNorm/beta, found name: bert/encoder/layer_5/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_6/attention/self/query/kernel, found name: bert/encoder/layer_6/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_6/attention/self/query/bias, found name: bert/encoder/layer_6/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_6/attention/self/key/kernel, found name: bert/encoder/layer_6/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_6/attention/self/key/bias, found name: bert/encoder/layer_6/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_6/attention/self/value/kernel, found name: bert/encoder/layer_6/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_6/attention/self/value/bias, found name: bert/encoder/layer_6/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_6/attention/output/dense/kernel, found name: bert/encoder/layer_6/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_6/attention/output/dense/bias, found name: bert/encoder/layer_6/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_6/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_6/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_6/attention/output/LayerNorm/beta, found name: bert/encoder/layer_6/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_6/intermediate/dense/kernel, found name: bert/encoder/layer_6/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_6/intermediate/dense/bias, found name: bert/encoder/layer_6/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_6/output/dense/kernel, found name: bert/encoder/layer_6/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_6/output/dense/bias, found name: bert/encoder/layer_6/output/dense/bias\n",
      "==> searching: bert/encoder/layer_6/output/LayerNorm/gamma, found name: bert/encoder/layer_6/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_6/output/LayerNorm/beta, found name: bert/encoder/layer_6/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_7/attention/self/query/kernel, found name: bert/encoder/layer_7/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_7/attention/self/query/bias, found name: bert/encoder/layer_7/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_7/attention/self/key/kernel, found name: bert/encoder/layer_7/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_7/attention/self/key/bias, found name: bert/encoder/layer_7/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_7/attention/self/value/kernel, found name: bert/encoder/layer_7/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_7/attention/self/value/bias, found name: bert/encoder/layer_7/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_7/attention/output/dense/kernel, found name: bert/encoder/layer_7/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_7/attention/output/dense/bias, found name: bert/encoder/layer_7/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_7/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_7/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_7/attention/output/LayerNorm/beta, found name: bert/encoder/layer_7/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_7/intermediate/dense/kernel, found name: bert/encoder/layer_7/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_7/intermediate/dense/bias, found name: bert/encoder/layer_7/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_7/output/dense/kernel, found name: bert/encoder/layer_7/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_7/output/dense/bias, found name: bert/encoder/layer_7/output/dense/bias\n",
      "==> searching: bert/encoder/layer_7/output/LayerNorm/gamma, found name: bert/encoder/layer_7/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_7/output/LayerNorm/beta, found name: bert/encoder/layer_7/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_8/attention/self/query/kernel, found name: bert/encoder/layer_8/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_8/attention/self/query/bias, found name: bert/encoder/layer_8/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_8/attention/self/key/kernel, found name: bert/encoder/layer_8/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_8/attention/self/key/bias, found name: bert/encoder/layer_8/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_8/attention/self/value/kernel, found name: bert/encoder/layer_8/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_8/attention/self/value/bias, found name: bert/encoder/layer_8/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_8/attention/output/dense/kernel, found name: bert/encoder/layer_8/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_8/attention/output/dense/bias, found name: bert/encoder/layer_8/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_8/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_8/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_8/attention/output/LayerNorm/beta, found name: bert/encoder/layer_8/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_8/intermediate/dense/kernel, found name: bert/encoder/layer_8/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_8/intermediate/dense/bias, found name: bert/encoder/layer_8/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_8/output/dense/kernel, found name: bert/encoder/layer_8/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_8/output/dense/bias, found name: bert/encoder/layer_8/output/dense/bias\n",
      "==> searching: bert/encoder/layer_8/output/LayerNorm/gamma, found name: bert/encoder/layer_8/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_8/output/LayerNorm/beta, found name: bert/encoder/layer_8/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_9/attention/self/query/kernel, found name: bert/encoder/layer_9/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_9/attention/self/query/bias, found name: bert/encoder/layer_9/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_9/attention/self/key/kernel, found name: bert/encoder/layer_9/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_9/attention/self/key/bias, found name: bert/encoder/layer_9/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_9/attention/self/value/kernel, found name: bert/encoder/layer_9/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_9/attention/self/value/bias, found name: bert/encoder/layer_9/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_9/attention/output/dense/kernel, found name: bert/encoder/layer_9/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_9/attention/output/dense/bias, found name: bert/encoder/layer_9/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_9/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_9/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_9/attention/output/LayerNorm/beta, found name: bert/encoder/layer_9/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_9/intermediate/dense/kernel, found name: bert/encoder/layer_9/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_9/intermediate/dense/bias, found name: bert/encoder/layer_9/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_9/output/dense/kernel, found name: bert/encoder/layer_9/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_9/output/dense/bias, found name: bert/encoder/layer_9/output/dense/bias\n",
      "==> searching: bert/encoder/layer_9/output/LayerNorm/gamma, found name: bert/encoder/layer_9/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_9/output/LayerNorm/beta, found name: bert/encoder/layer_9/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_10/attention/self/query/kernel, found name: bert/encoder/layer_10/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_10/attention/self/query/bias, found name: bert/encoder/layer_10/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_10/attention/self/key/kernel, found name: bert/encoder/layer_10/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_10/attention/self/key/bias, found name: bert/encoder/layer_10/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_10/attention/self/value/kernel, found name: bert/encoder/layer_10/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_10/attention/self/value/bias, found name: bert/encoder/layer_10/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_10/attention/output/dense/kernel, found name: bert/encoder/layer_10/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_10/attention/output/dense/bias, found name: bert/encoder/layer_10/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_10/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_10/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_10/attention/output/LayerNorm/beta, found name: bert/encoder/layer_10/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_10/intermediate/dense/kernel, found name: bert/encoder/layer_10/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_10/intermediate/dense/bias, found name: bert/encoder/layer_10/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_10/output/dense/kernel, found name: bert/encoder/layer_10/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_10/output/dense/bias, found name: bert/encoder/layer_10/output/dense/bias\n",
      "==> searching: bert/encoder/layer_10/output/LayerNorm/gamma, found name: bert/encoder/layer_10/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_10/output/LayerNorm/beta, found name: bert/encoder/layer_10/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_11/attention/self/query/kernel, found name: bert/encoder/layer_11/attention/self/query/kernel\n",
      "==> searching: bert/encoder/layer_11/attention/self/query/bias, found name: bert/encoder/layer_11/attention/self/query/bias\n",
      "==> searching: bert/encoder/layer_11/attention/self/key/kernel, found name: bert/encoder/layer_11/attention/self/key/kernel\n",
      "==> searching: bert/encoder/layer_11/attention/self/key/bias, found name: bert/encoder/layer_11/attention/self/key/bias\n",
      "==> searching: bert/encoder/layer_11/attention/self/value/kernel, found name: bert/encoder/layer_11/attention/self/value/kernel\n",
      "==> searching: bert/encoder/layer_11/attention/self/value/bias, found name: bert/encoder/layer_11/attention/self/value/bias\n",
      "==> searching: bert/encoder/layer_11/attention/output/dense/kernel, found name: bert/encoder/layer_11/attention/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_11/attention/output/dense/bias, found name: bert/encoder/layer_11/attention/output/dense/bias\n",
      "==> searching: bert/encoder/layer_11/attention/output/LayerNorm/gamma, found name: bert/encoder/layer_11/attention/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_11/attention/output/LayerNorm/beta, found name: bert/encoder/layer_11/attention/output/LayerNorm/beta\n",
      "==> searching: bert/encoder/layer_11/intermediate/dense/kernel, found name: bert/encoder/layer_11/intermediate/dense/kernel\n",
      "==> searching: bert/encoder/layer_11/intermediate/dense/bias, found name: bert/encoder/layer_11/intermediate/dense/bias\n",
      "==> searching: bert/encoder/layer_11/output/dense/kernel, found name: bert/encoder/layer_11/output/dense/kernel\n",
      "==> searching: bert/encoder/layer_11/output/dense/bias, found name: bert/encoder/layer_11/output/dense/bias\n",
      "==> searching: bert/encoder/layer_11/output/LayerNorm/gamma, found name: bert/encoder/layer_11/output/LayerNorm/gamma\n",
      "==> searching: bert/encoder/layer_11/output/LayerNorm/beta, found name: bert/encoder/layer_11/output/LayerNorm/beta\n",
      "==> searching: cls/predictions/transform/dense/kernel, found name: cls/predictions/transform/dense/kernel\n",
      "==> searching: cls/predictions/transform/dense/bias, found name: cls/predictions/transform/dense/bias\n",
      "==> searching: cls/predictions/transform/LayerNorm/gamma, found name: cls/predictions/transform/LayerNorm/gamma\n",
      "==> searching: cls/predictions/transform/LayerNorm/beta, found name: cls/predictions/transform/LayerNorm/beta\n",
      "==> searching: cls/predictions/output_bias, found name: cls/predictions/output_bias\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Sequence-Mask (Lambda)          (None, None)         0           Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Attention-Mask (Lambda)         (None, None, None)   0           Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, None, 768)    0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, None, 768)    0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, None, 768)    0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, None, 768)    0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, None, 768)    0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, None, 768)    0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, None, 768)    0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, None, 768)    0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, None, 768)    4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, None, 768)    0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, None, 768)    1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, None, 768)    4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, None, 768)    0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, None, 768)    1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, None, 768)    4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, None, 768)    0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, None, 768)    1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Sequence-Mask[0][0]              \n",
      "                                                                 Attention-Mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, None, 768)    4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, None, 768)    0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, None, 768)    1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, None, 768)    590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, None, 768)    1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Proba (EmbeddingDense)      (None, None, 21128)  21128       MLM-Norm[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 102,290,312\n",
      "Trainable params: 102,290,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/developer/wp/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_utils.py:819: UserWarning: Output MLM-Proba missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to MLM-Proba.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "model = build_bert_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    application='seq2seq',\n",
    "    # 只保留keep_words中的字，精简原字表\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 交叉熵作为loss，并mask掉输入部分的预测\n",
    "y_in = model.input[0][:, 1:]  # 目标tokens\n",
    "y_mask = model.input[1][:, 1:]\n",
    "y = model.output[:, :-1]  # 预测tokens，预测与目标错开一位\n",
    "cross_entropy = K.sparse_categorical_crossentropy(y_in, y)\n",
    "cross_entropy = K.sum(cross_entropy * y_mask) / K.sum(y_mask)\n",
    "\n",
    "model.add_loss(cross_entropy)\n",
    "model.compile(optimizer=Adam(1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:43:34.259070Z",
     "start_time": "2019-11-12T09:43:34.243991Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_sent(s, topk=3):\n",
    "    \"\"\"beam search解码\n",
    "    每次只保留topk个最优候选结果；如果topk=1，那么就是贪心搜索\n",
    "    \"\"\"\n",
    "    token_ids, segment_ids = tokenizer.encode(s[:max_input_len])\n",
    "    target_ids = [[] for _ in range(topk)]  # 候选答案id\n",
    "    target_scores = [0] * topk  # 候选答案分数\n",
    "    for i in range(max_output_len)[:3]:  # 强制要求输出不超过max_output_len字\n",
    "        _target_ids = [token_ids + t for t in target_ids]\n",
    "        print(\"_target_ids\",_target_ids)\n",
    "        _segment_ids = [segment_ids + [1] * len(t) for t in target_ids]\n",
    "        print(\"_segment_ids\",_segment_ids)\n",
    "        _probas = model.predict([_target_ids, _segment_ids\n",
    "                                 ])[: ,-1,100:]  # 直接忽略[PAD], [UNK], [CLS]\n",
    "        print(\"_probas\",_probas)\n",
    "        _log_probas = np.log(_probas + 1e-6)  # 取对数，方便计算\n",
    "        _topk_arg = _log_probas.argsort(axis=1)[:, -topk:]  # 每一项选出topk\n",
    "        _candidate_ids, _candidate_scores = [], []\n",
    "        for j, (ids, sco) in enumerate(zip(target_ids, target_scores)):\n",
    "            # 预测第一个字的时候，输入的topk事实上都是同一个，\n",
    "            # 所以只需要看第一个，不需要遍历后面的。\n",
    "            if i == 0 and j > 0:\n",
    "                continue\n",
    "            for k in _topk_arg[j]:\n",
    "                _candidate_ids.append(ids + [k + 3])\n",
    "                _candidate_scores.append(sco + _log_probas[j][k])\n",
    "        _topk_arg = np.argsort(_candidate_scores)[-topk:]  # 从中选出新的topk\n",
    "        target_ids = [_candidate_ids[k] for k in _topk_arg]\n",
    "        print(\"target_ids\",target_ids)\n",
    "        target_scores = [_candidate_scores[k] for k in _topk_arg]\n",
    "        print(\"target_scores\", target_scores)\n",
    "        best_one = np.argmax(target_scores)\n",
    "        if target_ids[best_one][-1] == 10:\n",
    "            return tokenizer.decode(target_ids[best_one])\n",
    "    # 如果max_output_len字都找不到结束符，直接返回\n",
    "    return tokenizer.decode(target_ids[np.argmax(target_scores)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T09:43:58.500008Z",
     "start_time": "2019-11-12T09:43:39.975581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_target_ids [[101, 5835, 5855, 6037, 131, 102], [101, 5835, 5855, 6037, 131, 102], [101, 5835, 5855, 6037, 131, 102]]\n",
      "_segment_ids [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
      "_probas [[6.38667261e-05 2.24637144e-08 5.70373295e-08 ... 1.10356568e-08\n",
      "  1.62667335e-09 1.15774865e-08]\n",
      " [6.38667261e-05 2.24637144e-08 5.70373295e-08 ... 1.10356568e-08\n",
      "  1.62667335e-09 1.15774865e-08]\n",
      " [6.38667261e-05 2.24637482e-08 5.70373082e-08 ... 1.10356746e-08\n",
      "  1.62667591e-09 1.15775149e-08]]\n",
      "target_ids [[1929], [4417], [4276]]\n",
      "target_scores [-3.4190540313720703, -3.100290298461914, -2.9956352710723877]\n",
      "_target_ids [[101, 5835, 5855, 6037, 131, 102, 1929], [101, 5835, 5855, 6037, 131, 102, 4417], [101, 5835, 5855, 6037, 131, 102, 4276]]\n",
      "_segment_ids [[0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1]]\n",
      "_probas [[1.9493209e-05 5.7843141e-10 5.3411046e-13 ... 1.1163006e-09\n",
      "  2.4262787e-09 1.3938489e-11]\n",
      " [1.2881893e-10 7.7174579e-13 3.0951424e-14 ... 1.3348185e-12\n",
      "  3.0899166e-14 6.2881699e-13]\n",
      " [2.5195943e-05 2.4811520e-10 6.0203198e-10 ... 5.7918634e-09\n",
      "  1.1694519e-10 3.0595249e-08]]\n",
      "target_ids [[1929, 2158], [4276, 5573], [4417, 4364]]\n",
      "target_scores [-4.162601828575134, -4.082828164100647, -3.1003195647699613]\n",
      "_target_ids [[101, 5835, 5855, 6037, 131, 102, 1929, 2158], [101, 5835, 5855, 6037, 131, 102, 4276, 5573], [101, 5835, 5855, 6037, 131, 102, 4417, 4364]]\n",
      "_segment_ids [[0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 1, 1]]\n",
      "_probas [[7.3010125e-04 4.2283486e-13 8.1826923e-13 ... 3.6060804e-11\n",
      "  6.3803224e-10 4.7894331e-11]\n",
      " [1.2812316e-07 1.5027846e-13 2.1628023e-12 ... 2.4238617e-10\n",
      "  1.3813514e-10 1.3543670e-11]\n",
      " [1.4173908e-09 4.4684621e-11 3.8837485e-11 ... 5.0363874e-10\n",
      "  1.3888656e-09 4.8893334e-11]]\n",
      "target_ids [[4276, 5573, 2447], [4417, 4364, 685], [4417, 4364, 7502]]\n",
      "target_scores [-4.204810746014118, -4.1755341891748685, -3.9087749723894376]\n",
      "生成词: 琉獵韓\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def just_show():\n",
    "    s1 = \"菩萨蛮:\"\n",
    "#     s2 = \"踏莎行:\"\n",
    "#     for s in [s1, s2]:\n",
    "    print('生成词:', gen_sent(s1))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "class Evaluate(Callback):\n",
    "    def __init__(self):\n",
    "        self.lowest = 1e10\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 保存最优\n",
    "        if logs['loss'] <= self.lowest:\n",
    "            self.lowest = logs['loss']\n",
    "            model.save_weights('./best_model.weights')\n",
    "        # 演示效果\n",
    "        just_show()\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "steps_per_epoch = 1000  \n",
    "epochs = 100\n",
    "max_input_len = 32\n",
    "max_output_len = 256\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "#     evaluator = Evaluate()\n",
    "\n",
    "#     model.fit_generator(data_generator(),\n",
    "#                         steps_per_epoch=steps_per_epoch,\n",
    "#                         epochs=epochs,\n",
    "#                         callbacks=[evaluator])\n",
    "    model.load_weights(\"best_model.weights\")\n",
    "    just_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
